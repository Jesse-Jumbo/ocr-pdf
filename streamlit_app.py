#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR Webæ‡‰ç”¨ - å®Œå…¨å…è²»ç‰ˆæœ¬
æ”¯æŒTesseractå’ŒPaddleOCRå…©ç¨®OCRå¼•æ“
"""

import streamlit as st
import os
import json
import tempfile
import time
from pathlib import Path
import logging

# è¨­ç½®é é¢é…ç½®
st.set_page_config(
    page_title="å…è²»OCRæ–‡æœ¬è­˜åˆ¥ç³»çµ±",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ è‡ªå®šç¾©CSS
st.markdown("""
<style>
.scrollable-container {
    max-height: 600px;
    overflow-y: auto;
    border: 1px solid #e0e0e0;
    border-radius: 5px;
    padding: 10px;
    background-color: #fafafa;
}
</style>
""", unsafe_allow_html=True)

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å»¶é²å°å…¥OCRç›¸é—œåº«
try:
    import cv2
    import numpy as np
    from PIL import Image
    import pdf2image
    from paddleocr import PaddleOCR
    import pytesseract
    st.success("âœ… æ‰€æœ‰OCRä¾è³´åº«å°å…¥æˆåŠŸ")
    OCR_AVAILABLE = True
except ImportError as e:
    st.error(f"âŒ OCRä¾è³´åº«å°å…¥å¤±æ•—: {e}")
    st.error("è«‹ç¢ºä¿æ‰€æœ‰ä¾è³´éƒ½å·²æ­£ç¢ºå®‰è£")
    OCR_AVAILABLE = False

class TesseractOCR:
    """Tesseract OCRè™•ç†å™¨ - å®Œå…¨å…è²»"""
    
    def __init__(self):
        """åˆå§‹åŒ–Tesseract OCR"""
        # è¨­ç½®Tesseractè·¯å¾‘ (è‡ªå‹•æª¢æ¸¬)
        import shutil
        tesseract_path = shutil.which('tesseract')
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
        else:
            # å¸¸è¦‹è·¯å¾‘
            possible_paths = [
                '/opt/homebrew/bin/tesseract',  # macOS Homebrew
                '/usr/local/bin/tesseract',     # macOS/Linux
                '/usr/bin/tesseract',           # Linux
                'tesseract'                     # ç³»çµ±PATH
            ]
            for path in possible_paths:
                if shutil.which(path):
                    pytesseract.pytesseract.tesseract_cmd = path
                    break
    
    def pdf_to_images(self, pdf_path: str, dpi: int = 300):
        """å°‡PDFè½‰æ›ç‚ºåœ–åƒ"""
        try:
            images = pdf2image.convert_from_path(
                pdf_path, 
                dpi=dpi,
                first_page=None,
                last_page=None,
                fmt='RGB',
                thread_count=4,
                poppler_path=None,
                grayscale=False,
                size=None,
                transparent=False,
                single_file=False,
                output_file=None,
                jpegopt=None,
                strict=False,
                use_pdftocairo=False,
                timeout=600
            )
            return [np.array(img) for img in images]
        except Exception as e:
            logger.error(f"PDFè½‰æ›å¤±æ•—: {e}")
            return []
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """åœ–åƒé è™•ç†"""
        # è½‰æ›ç‚ºç°åº¦
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image.copy()
        
        # å»å™ª
        denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)
        
        # å°æ¯”åº¦å¢å¼·
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        # éŠ³åŒ–
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        # äºŒå€¼åŒ–
        binary = cv2.adaptiveThreshold(
            sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        return binary
    
    def extract_text(self, image: np.ndarray) -> list:
        """ä½¿ç”¨Tesseractæå–æ–‡æœ¬ - æ”¹å–„æ¨™é»ç¬¦è™Ÿå’Œæ¨™é¡Œè­˜åˆ¥"""
        try:
            # é è™•ç†åœ–åƒ
            processed_image = self.preprocess_image(image)
            
            # ä½¿ç”¨å¤šç¨®é…ç½®ä¾†æ”¹å–„è­˜åˆ¥
            configs = [
                '--psm 3 -c preserve_interword_spaces=1 -c textord_min_linesize=1.5 -c textord_old_baselines=0',
                '--psm 4 -c preserve_interword_spaces=1 -c textord_min_linesize=1.5',
                '--psm 6 -c preserve_interword_spaces=1 -c textord_min_linesize=1.5'
            ]
            
            lang = 'chi_tra+chi_sim+eng'  # ç¹é«”ä¸­æ–‡+ç°¡é«”ä¸­æ–‡+è‹±æ–‡
            best_result = ""
            best_confidence = 0
            
            # å˜—è©¦å¤šç¨®é…ç½®ï¼Œé¸æ“‡æœ€ä½³çµæœ
            for config in configs:
                try:
                    text_result = pytesseract.image_to_string(
                        processed_image, 
                        lang=lang, 
                        config=config
                    )
                    
                    # è¨ˆç®—å¹³å‡ç½®ä¿¡åº¦
                    data = pytesseract.image_to_data(
                        processed_image, 
                        lang=lang, 
                        config=config, 
                        output_type=pytesseract.Output.DICT
                    )
                    
                    confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
                    avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                    
                    if avg_confidence > best_confidence:
                        best_result = text_result
                        best_confidence = avg_confidence
                        best_data = data
                        
                except Exception as e:
                    logger.warning(f"Tesseracté…ç½® {config} å¤±æ•—: {e}")
                    continue
            
            if not best_result:
                return []
            
            # å¾Œè™•ç†æ–‡æœ¬ï¼Œæ”¹å–„æ¨™é»ç¬¦è™Ÿè­˜åˆ¥
            processed_text = self._post_process_text(best_result)
            lines = processed_text.strip().split('\n')
            
            # å‰µå»ºæ–‡æœ¬å¡Š
            text_blocks = []
            current_line = ""
            current_y = None
            current_x = 0
            current_width = 0
            current_height = 0
            max_confidence = 0
            
            for i in range(len(best_data['text'])):
                text = best_data['text'][i].strip()
                confidence = int(best_data['conf'][i])
                x = best_data['left'][i]
                y = best_data['top'][i]
                width = best_data['width'][i]
                height = best_data['height'][i]
                
                if text and confidence > 30:
                    # å¦‚æœæ˜¯æ–°è¡Œæˆ–ä½ç½®å·®è·è¼ƒå¤§ï¼Œä¿å­˜ç•¶å‰è¡Œ
                    if current_y is not None and abs(y - current_y) > 15:
                        if current_line.strip():
                            # å¾Œè™•ç†ç•¶å‰è¡Œ
                            processed_line = self._post_process_text(current_line.strip())
                            text_blocks.append({
                                "text": processed_line,
                                "confidence": max_confidence / 100.0,
                                "position": {
                                    "x": current_x,
                                    "y": current_y,
                                    "width": current_width,
                                    "height": current_height
                                }
                            })
                        current_line = text
                        current_y = y
                        current_x = x
                        current_width = width
                        current_height = height
                        max_confidence = confidence
                    else:
                        # åŒä¸€è¡Œï¼Œç´¯ç©æ–‡æœ¬
                        if current_line:
                            current_line += text
                        else:
                            current_line = text
                            current_y = y
                            current_x = x
                            current_width = width
                            current_height = height
                            max_confidence = confidence
                        
                        # æ›´æ–°ä½ç½®ä¿¡æ¯
                        current_width = max(current_width, x + width - current_x)
                        current_height = max(current_height, y + height - current_y)
                        max_confidence = max(max_confidence, confidence)
            
            # ä¿å­˜æœ€å¾Œä¸€è¡Œ
            if current_line.strip():
                processed_line = self._post_process_text(current_line.strip())
                text_blocks.append({
                    "text": processed_line,
                    "confidence": max_confidence / 100.0,
                    "position": {
                        "x": current_x,
                        "y": current_y,
                        "width": current_width,
                        "height": current_height
                    }
                })
            
            return text_blocks
            
        except Exception as e:
            logger.error(f"Tesseract OCRå¤±æ•—: {e}")
            return []
    
    def _post_process_text(self, text: str) -> str:
        """å¾Œè™•ç†æ–‡æœ¬ï¼Œæ”¹å–„æ¨™é»ç¬¦è™Ÿå’Œæ ¼å¼"""
        if not text:
            return text
        
        # ä¿®å¾©å¸¸è¦‹çš„æ¨™é»ç¬¦è™Ÿè­˜åˆ¥éŒ¯èª¤
        replacements = {
            # ä¿®å¾©å¥è™Ÿ
            'ã€‚': 'ã€‚',
            'ï¼': 'ã€‚',
            'Â·': 'ã€‚',
            'â€¢': 'ã€‚',
            'o': 'ã€‚',
            'O': 'ã€‚',
            '0': 'ã€‚',
            
            # ä¿®å¾©é€—è™Ÿ
            'ï¼Œ': 'ï¼Œ',
            ',': 'ï¼Œ',
            'ã€': 'ï¼Œ',
            
            # ä¿®å¾©å†’è™Ÿ
            'ï¼š': 'ï¼š',
            ':': 'ï¼š',
            
            # ä¿®å¾©åˆ†è™Ÿ
            'ï¼›': 'ï¼›',
            ';': 'ï¼›',
            
            # ä¿®å¾©å•è™Ÿ
            'ï¼Ÿ': 'ï¼Ÿ',
            '?': 'ï¼Ÿ',
            
            # ä¿®å¾©æ„Ÿå˜†è™Ÿ
            'ï¼': 'ï¼',
            '!': 'ï¼',
            
            # ä¿®å¾©æ‹¬è™Ÿ
            'ï¼ˆ': 'ï¼ˆ',
            '(': 'ï¼ˆ',
            'ï¼‰': 'ï¼‰',
            ')': 'ï¼‰',
            
            # ä¿®å¾©å¼•è™Ÿ
            '"': '"',
            '"': '"',
            "'": "'",
            "'": "'",
            
            # ä¿®å¾©ç ´æŠ˜è™Ÿ
            'â€”': 'â€”',
            '-': 'â€”',
            'â€“': 'â€”',
            
            # ä¿®å¾©çœç•¥è™Ÿ
            'â€¦': 'â€¦',
            '...': 'â€¦',
        }
        
        # æ‡‰ç”¨æ›¿æ›
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # ä¿®å¾©å¸¸è¦‹çš„è­˜åˆ¥éŒ¯èª¤
        text = text.replace('o ', 'ã€‚')  # o å¾Œé¢è·Ÿç©ºæ ¼ -> å¥è™Ÿ
        text = text.replace('o\n', 'ã€‚\n')  # o å¾Œé¢è·Ÿæ›è¡Œ -> å¥è™Ÿ
        text = text.replace('o', 'ã€‚')  # å–®ç¨çš„ o -> å¥è™Ÿ
        
        # ä¿®å¾©åˆ—è¡¨ç¬¦è™Ÿ
        text = text.replace('o ', 'â€¢ ')  # o é–‹é ­ -> åˆ—è¡¨ç¬¦è™Ÿ
        text = text.replace('o\n', 'â€¢\n')  # o é–‹é ­æ›è¡Œ -> åˆ—è¡¨ç¬¦è™Ÿ
        
        # ä¿®å¾©æ¨™é¡Œè­˜åˆ¥ï¼ˆå¤§å¯«å­—æ¯é–‹é ­ä¸”è¼ƒçŸ­çš„è¡Œï¼‰
        lines = text.split('\n')
        processed_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                processed_lines.append(line)
                continue
                
            # æª¢æŸ¥æ˜¯å¦å¯èƒ½æ˜¯æ¨™é¡Œ
            if (len(line) < 50 and 
                (line[0].isupper() or line[0].isdigit()) and
                not line.endswith(('ã€‚', 'ï¼Œ', 'ï¼š', 'ï¼›', 'ï¼Ÿ', 'ï¼'))):
                # å¯èƒ½æ˜¯æ¨™é¡Œï¼Œç¢ºä¿ä»¥å¥è™Ÿçµå°¾
                if not line.endswith('ã€‚'):
                    line += 'ã€‚'
            
            processed_lines.append(line)
        
        return '\n'.join(processed_lines)
    
    def _merge_nearby_texts(self, texts: list) -> list:
        """åˆä½µç›¸è¿‘çš„æ–‡æœ¬ï¼Œè§£æ±ºæ–·å¥å•é¡Œ"""
        if not texts:
            return []
        
        # æŒ‰ä½ç½®æ’åº
        sorted_texts = sorted(texts, key=lambda x: (x["position"]["y"], x["position"]["x"]))
        merged_texts = []
        
        for text_data in sorted_texts:
            if not merged_texts:
                merged_texts.append(text_data)
                continue
            
            last_text = merged_texts[-1]
            
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åˆä½µ
            should_merge = False
            
            # 1. æª¢æŸ¥å‚ç›´ä½ç½®æ˜¯å¦ç›¸è¿‘ï¼ˆåŒä¸€è¡Œï¼‰
            y_diff = abs(text_data["position"]["y"] - last_text["position"]["y"])
            if y_diff < 20:  # 20åƒç´ å…§è¦–ç‚ºåŒä¸€è¡Œ
                # 2. æª¢æŸ¥æ°´å¹³ä½ç½®æ˜¯å¦é€£çºŒ
                x_gap = text_data["position"]["x"] - (last_text["position"]["x"] + last_text["position"]["width"])
                if x_gap < 50:  # 50åƒç´ å…§è¦–ç‚ºé€£çºŒæ–‡æœ¬
                    should_merge = True
            
            if should_merge:
                # åˆä½µæ–‡æœ¬
                merged_text = last_text["text"] + text_data["text"]
                merged_position = {
                    "x": min(last_text["position"]["x"], text_data["position"]["x"]),
                    "y": min(last_text["position"]["y"], text_data["position"]["y"]),
                    "width": max(last_text["position"]["x"] + last_text["position"]["width"], 
                               text_data["position"]["x"] + text_data["position"]["width"]) - 
                            min(last_text["position"]["x"], text_data["position"]["x"]),
                    "height": max(last_text["position"]["y"] + last_text["position"]["height"], 
                                text_data["position"]["y"] + text_data["position"]["height"]) - 
                             min(last_text["position"]["y"], text_data["position"]["y"])
                }
                
                # æ›´æ–°æœ€å¾Œä¸€å€‹æ–‡æœ¬
                merged_texts[-1] = {
                    "text": merged_text,
                    "confidence": max(last_text["confidence"], text_data["confidence"]),
                    "position": merged_position
                }
            else:
                merged_texts.append(text_data)
        
        return merged_texts
    
    def _deduplicate_texts(self, texts: list) -> list:
        """å»é‡æ–‡æœ¬"""
        unique_texts = []
        for text_data in texts:
            is_duplicate = False
            for existing in unique_texts:
                if (self._texts_overlap(text_data, existing) and 
                    abs(len(text_data["text"]) - len(existing["text"])) < 2):
                    if text_data["confidence"] > existing["confidence"]:
                        unique_texts.remove(existing)
                        unique_texts.append(text_data)
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_texts.append(text_data)
        
        return unique_texts
    
    def _texts_overlap(self, text1: dict, text2: dict) -> bool:
        """æª¢æŸ¥æ–‡æœ¬æ˜¯å¦é‡ç–Š"""
        pos1 = text1["position"]
        pos2 = text2["position"]
        
        overlap_x = not (pos1["x"] + pos1["width"] < pos2["x"] or pos2["x"] + pos2["width"] < pos1["x"])
        overlap_y = not (pos1["y"] + pos1["height"] < pos2["y"] or pos2["y"] + pos2["height"] < pos1["y"])
        
        return overlap_x and overlap_y


def process_pdf_with_ocr(pdf_path: str, ocr_engine: str, dpi: int = 300, progress_callback=None) -> dict:
    """ä½¿ç”¨Tesseract OCRè™•ç†PDF - æ”¯æŒå³æ™‚å›èª¿"""
    try:
        # åªä½¿ç”¨Tesseract
        ocr_processor = TesseractOCR()
        
        # è½‰æ›PDFç‚ºåœ–åƒ
        images = ocr_processor.pdf_to_images(pdf_path, dpi=dpi)
        
        if not images:
            return {"error": "PDFè½‰æ›å¤±æ•—"}
        
        result = {
            "file_name": os.path.basename(pdf_path),
            "total_pages": len(images),
            "pages": [],
            "ocr_engine": "Tesseract"
        }
        
        # è™•ç†æ¯ä¸€é 
        for page_num, image in enumerate(images, 1):
            if progress_callback:
                progress_callback(f"æ­£åœ¨è™•ç†ç¬¬ {page_num} é ...", page_num, len(images))
            
            texts = ocr_processor.extract_text(image)
            
            # ç›´æ¥ä½¿ç”¨æ–‡æœ¬ï¼Œä¿æŒåŸå§‹æ ¼å¼
            page_result = {
                "page_number": page_num,
                "text_blocks": texts,
                "full_text": "\n".join([block["text"] for block in texts])
            }
            result["pages"].append(page_result)
            
            # å³æ™‚å›èª¿ï¼Œè®“UIæ›´æ–°
            if progress_callback:
                progress_callback(f"ç¬¬ {page_num} é è™•ç†å®Œæˆ", page_num, len(images), result)
        
        return result
        
    except Exception as e:
        return {"error": f"OCRè™•ç†å¤±æ•—: {str(e)}"}

def display_results(result: dict):
    """é¡¯ç¤ºè™•ç†çµæœ"""
    st.markdown("### ğŸ“Š è™•ç†çµæœæ¦‚è¦½")
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¸½é æ•¸", result["total_pages"])
    
    with col2:
        total_blocks = sum(len(page["text_blocks"]) for page in result["pages"])
        st.metric("æ–‡æœ¬å¡Šç¸½æ•¸", total_blocks)
    
    with col3:
        st.metric("OCRå¼•æ“", result["ocr_engine"])
    
    with col4:
        avg_confidence = sum(
            sum(block["confidence"] for block in page["text_blocks"]) 
            for page in result["pages"]
        ) / max(total_blocks, 1)
        st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
    
    # é é¢é¸æ“‡å™¨
    st.markdown("### ğŸ“„ é é¢è©³ç´°ä¿¡æ¯")
    page_options = [f"ç¬¬ {page['page_number']} é " for page in result["pages"]]
    selected_page_idx = st.selectbox("é¸æ“‡è¦æŸ¥çœ‹çš„é é¢:", range(len(page_options)), format_func=lambda x: page_options[x])
    
    if selected_page_idx is not None:
        selected_page = result["pages"][selected_page_idx]
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### é é¢ä¿¡æ¯")
            st.write(f"**é ç¢¼:** {selected_page['page_number']}")
            st.write(f"**æ–‡æœ¬å¡Šæ•¸é‡:** {len(selected_page['text_blocks'])}")
            
            if selected_page["text_blocks"]:
                avg_conf = sum(block["confidence"] for block in selected_page["text_blocks"]) / len(selected_page["text_blocks"])
                st.write(f"**å¹³å‡ç½®ä¿¡åº¦:** {avg_conf:.2f}")
        
        with col2:
            st.markdown("#### è­˜åˆ¥æ–‡æœ¬")
            if selected_page["text_blocks"]:
                for i, block in enumerate(selected_page["text_blocks"]):
                    st.write(f"**{i+1}.** {block['text']} (ç½®ä¿¡åº¦: {block['confidence']:.2f})")
            else:
                st.write("æ­¤é é¢æ²’æœ‰è­˜åˆ¥åˆ°æ–‡æœ¬")

def display_comparison_view(result: dict, pdf_images=None):
    """é¡¯ç¤ºå°æ¯”è¦–çª— - åŸæ–‡ä»¶èˆ‡è­˜åˆ¥çµæœä¸¦æ’é¡¯ç¤º"""
    st.markdown("### ğŸ” åŸæ–‡ä»¶èˆ‡è­˜åˆ¥çµæœå°æ¯”")
    
    # å‰µå»ºå…©åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ“„ åŸæ–‡ä»¶")
        if pdf_images:
            # åœ¨å¯æ»¾å‹•çš„å®¹å™¨ä¸­é¡¯ç¤ºæ‰€æœ‰é é¢
            st.markdown('<div class="scrollable-container">', unsafe_allow_html=True)
            for i, image in enumerate(pdf_images):
                st.image(image, caption=f"ç¬¬ {i+1} é ", use_column_width=True)
                if i < len(pdf_images) - 1:  # ä¸åœ¨æœ€å¾Œä¸€é å¾Œæ·»åŠ åˆ†éš”ç·š
                    st.markdown("---")
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("åŸæ–‡ä»¶åœ–åƒé è¦½åŠŸèƒ½éœ€è¦é‡æ–°ä¸Šå‚³æ–‡ä»¶")
    
    with col2:
        st.markdown("#### ğŸ“ è­˜åˆ¥çµæœ")
        
        # é é¢é¸æ“‡å™¨
        page_options = [f"ç¬¬ {page['page_number']} é " for page in result["pages"]]
        selected_page_idx = st.selectbox("é¸æ“‡è¦æŸ¥çœ‹çš„é é¢:", range(len(page_options)), format_func=lambda x: page_options[x])
        
        if selected_page_idx is not None:
            selected_page = result["pages"][selected_page_idx]
            
            if selected_page["text_blocks"]:
                # é¡¯ç¤ºè­˜åˆ¥åˆ°çš„æ–‡æœ¬
                for i, block in enumerate(selected_page["text_blocks"]):
                    st.write(f"**{i+1}.** {block['text']}")
            else:
                st.write("æ­¤é é¢æ²’æœ‰è­˜åˆ¥åˆ°æ–‡æœ¬")
            
            # é¡¯ç¤ºå®Œæ•´æ–‡æœ¬
            st.markdown("#### ğŸ“„ å®Œæ•´æ–‡æœ¬")
            st.text_area("è­˜åˆ¥çµæœ:", value=selected_page['full_text'], height=300, key=f"text_area_{selected_page_idx}")

def download_text_file(result: dict, key_suffix: str = ""):
    """ä¸‹è¼‰æ–‡æœ¬æ–‡ä»¶"""
    full_text = "\n\n".join([f"=== ç¬¬ {page['page_number']} é  ===" + "\n" + page['full_text'] for page in result["pages"]])
    
    st.download_button(
        label="ğŸ“ ä¸‹è¼‰TXTæ–‡ä»¶",
        data=full_text,
        file_name=f"{result['file_name']}_text.txt",
        mime="text/plain",
        key=f"download_txt_{key_suffix}_{int(time.time())}"
    )

def download_json_file(result: dict, key_suffix: str = ""):
    """ä¸‹è¼‰JSONæ–‡ä»¶"""
    # ç°¡åŒ–çš„JSONæ ¼å¼ï¼ˆç´”æ–‡å­—ï¼‰
    simplified_result = {
        "file_name": result["file_name"],
        "total_pages": result["total_pages"],
        "ocr_engine": result["ocr_engine"],
        "pages": []
    }
    
    for page in result["pages"]:
        simplified_page = {
            "page_number": page["page_number"],
            "text": page["full_text"]  # åªä¿ç•™ç´”æ–‡å­—
        }
        simplified_result["pages"].append(simplified_page)
    
    json_data = json.dumps(simplified_result, ensure_ascii=False, indent=2)
    
    st.download_button(
        label="ğŸ“„ ä¸‹è¼‰JSONæ–‡ä»¶",
        data=json_data,
        file_name=f"{result['file_name']}_ocr.json",
        mime="application/json",
        key=f"download_json_{key_suffix}_{int(time.time())}"
    )

def main():
    """ä¸»å‡½æ•¸"""
    # æ¨™é¡Œ
    st.markdown('<h1 class="main-header">ğŸ“„ å…è²»OCRæ–‡æœ¬è­˜åˆ¥ç³»çµ±</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ä½¿ç”¨Tesseract OCRå¼•æ“ï¼Œå®Œå…¨ä¿ç•™æ–‡å­—æ¨£å¼å’Œæ–·å¥</p>', unsafe_allow_html=True)
    
    # æª¢æŸ¥OCRå¯ç”¨æ€§
    if not OCR_AVAILABLE:
        st.error("âŒ OCRä¾è³´åº«æœªæ­£ç¢ºå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨OCRåŠŸèƒ½")
        st.markdown("### è«‹æª¢æŸ¥ä»¥ä¸‹ä¾è³´æ˜¯å¦æ­£ç¢ºå®‰è£ï¼š")
        st.code("""
        pip install streamlit numpy Pillow opencv-python-headless
        pip install pytesseract pdf2image
        """)
        st.stop()
    
    # åˆå§‹åŒ–session state
    if 'processing_results' not in st.session_state:
        st.session_state.processing_results = None
    if 'current_file' not in st.session_state:
        st.session_state.current_file = None
    if 'is_processing' not in st.session_state:
        st.session_state.is_processing = False
    if 'history' not in st.session_state:
        st.session_state.history = []
    if 'pdf_images' not in st.session_state:
        st.session_state.pdf_images = None
    if 'current_progress' not in st.session_state:
        st.session_state.current_progress = None
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.markdown("## ğŸ”§ OCRå¼•æ“")
        
        # å›ºå®šä½¿ç”¨Tesseract
        ocr_engine = "Tesseract"
        st.success("âœ… ä½¿ç”¨ Tesseract OCR")
        
        # è™•ç†åƒæ•¸
        st.markdown("### è™•ç†åƒæ•¸")
        dpi = st.slider("åœ–åƒDPI", 150, 600, 300, help="æ›´é«˜çš„DPIæœƒæé«˜è­˜åˆ¥ç²¾åº¦ä½†è™•ç†æ™‚é–“æ›´é•·")
        
        # å¼•æ“ä¿¡æ¯
        st.markdown("### â„¹ï¸ å¼•æ“ä¿¡æ¯")
        st.info("**Tesseract OCR**\n- å®Œå…¨å…è²»\n- ç©©å®šå¯é \n- æ”¯æŒå¤šèªè¨€\n- è™•ç†é€Ÿåº¦è¼ƒå¿«\n- å®Œå…¨ä¿ç•™æ–‡å­—æ¨£å¼å’Œæ–·å¥\n- å„ªåŒ–çš„ä¸­æ–‡è­˜åˆ¥")
        
        # æ­·å²è¨˜éŒ„
        if st.session_state.history:
            st.markdown("### ğŸ“š æ­·å²è¨˜éŒ„")
            for i, item in enumerate(st.session_state.history):
                with st.expander(f"ğŸ“„ {item['file_name']} ({item['total_pages']}é )"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if st.button("ğŸ‘ï¸ é è¦½", key=f"preview_{i}"):
                            st.session_state.processing_results = item
                            st.session_state.current_file = item['file_name']
                    with col2:
                        download_text_file(item, f"hist_{i}")
                    with col3:
                        download_json_file(item, f"hist_{i}")
    
    # ä¸»è¦å…§å®¹
    st.markdown("### ğŸ“¤ ä¸Šå‚³PDFæ–‡ä»¶")
    
    # æ–‡ä»¶ä¸Šå‚³
    uploaded_file = st.file_uploader(
        "é¸æ“‡PDFæ–‡ä»¶",
        type=['pdf'],
        help="æ”¯æŒä¸­æ–‡æ–‡æœ¬çš„PDFæ–‡ä»¶"
    )
    
    # å¦‚æœæœ‰è™•ç†çµæœï¼Œé¡¯ç¤ºä¸‹è¼‰æŒ‰éˆ•
    if st.session_state.processing_results:
        st.markdown("### ğŸ’¾ ä¸‹è¼‰çµæœ")
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            download_text_file(st.session_state.processing_results, "main")
        
        with col2:
            download_json_file(st.session_state.processing_results, "main")
        
        with col3:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤çµæœ", type="secondary"):
                st.session_state.processing_results = None
                st.session_state.current_file = None
                st.rerun()
    
    if uploaded_file is not None:
        # é¡¯ç¤ºæ–‡ä»¶ä¿¡æ¯
        st.markdown("#### æ–‡ä»¶ä¿¡æ¯")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write(f"**æ–‡ä»¶å:** {uploaded_file.name}")
        with col2:
            st.write(f"**æ–‡ä»¶å¤§å°:** {uploaded_file.size / 1024 / 1024:.2f} MB")
        with col3:
            st.write(f"**OCRå¼•æ“:** {ocr_engine}")
        
        # ä¿å­˜æ–‡ä»¶åˆ°è‡¨æ™‚ç›®éŒ„
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # è™•ç†æŒ‰éˆ•
        if st.button("ğŸš€ é–‹å§‹OCRè™•ç†", type="primary"):
            st.session_state.is_processing = True
            
            # å‰µå»ºé€²åº¦æ¢å’Œç‹€æ…‹é¡¯ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # è½‰æ›æ‰€æœ‰é é¢ç‚ºåœ–åƒä¸¦ä¿å­˜åˆ°session state
            all_images = pdf2image.convert_from_path(tmp_file_path, dpi=150)
            st.session_state.pdf_images = all_images
            
            # å®šç¾©é€²åº¦å›èª¿å‡½æ•¸
            def progress_callback(message, current_page, total_pages, partial_result=None):
                progress = current_page / total_pages
                progress_bar.progress(progress)
                status_text.text(f"{message} ({current_page}/{total_pages})")
            
            # è™•ç†æ–‡ä»¶
            result = process_pdf_with_ocr(tmp_file_path, ocr_engine, dpi, progress_callback)
            
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            os.unlink(tmp_file_path)
            
            if "error" in result:
                st.error(f"âŒ {result['error']}")
                st.session_state.is_processing = False
            else:
                progress_bar.progress(100)
                status_text.text("è™•ç†å®Œæˆï¼")
                st.success("âœ… OCRè™•ç†å®Œæˆï¼")
                
                # ä¿å­˜çµæœåˆ°session state
                st.session_state.processing_results = result
                st.session_state.current_file = uploaded_file.name
                
                # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
                if result not in st.session_state.history:
                    st.session_state.history.insert(0, result)
                    # é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
                    if len(st.session_state.history) > 10:
                        st.session_state.history = st.session_state.history[:10]
                
                st.session_state.is_processing = False
                st.rerun()
    
    # å¦‚æœæœ‰è™•ç†çµæœï¼Œé¡¯ç¤ºå°æ¯”è¦–çª—
    if st.session_state.processing_results and not st.session_state.is_processing:
        display_comparison_view(st.session_state.processing_results, st.session_state.pdf_images)
    
    # ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“š ä½¿ç”¨èªªæ˜"):
        st.markdown("""
        #### ğŸ¯ åŠŸèƒ½ç‰¹é»
        
        - **Tesseract OCR**: ä½¿ç”¨ç©©å®šå¯é çš„Tesseract OCRå¼•æ“
        - **å®Œå…¨å…è²»**: æ‰€æœ‰åŠŸèƒ½å®Œå…¨å…è²»ï¼Œç„¡éœ€APIå¯†é‘°
        - **ä¸­æ–‡å„ªåŒ–**: é‡å°ä¸­æ–‡å­—é«”å„ªåŒ–ï¼Œå®Œå…¨ä¿ç•™æ–‡å­—æ¨£å¼å’Œæ–·å¥
        - **å¤šæ ¼å¼è¼¸å‡º**: æ”¯æŒJSONå’Œæ–‡æœ¬æ ¼å¼ä¸‹è¼‰
        - **æ­·å²è¨˜éŒ„**: ä¿å­˜è™•ç†æ­·å²ï¼Œæ–¹ä¾¿é‡æ–°ä¸‹è¼‰
        - **å°æ¯”è¦–çª—**: åŸæ–‡ä»¶èˆ‡è­˜åˆ¥çµæœä¸¦æ’é¡¯ç¤º
        
        #### ğŸ“‹ ä½¿ç”¨æ­¥é©Ÿ
        
        1. **ä¸Šå‚³æ–‡ä»¶**: é¸æ“‡è¦è™•ç†çš„PDFæ–‡ä»¶
        2. **é è¦½æ–‡ä»¶**: æŸ¥çœ‹æ–‡ä»¶ç¬¬ä¸€é é è¦½
        3. **é–‹å§‹è™•ç†**: é»æ“Š"é–‹å§‹OCRè™•ç†"æŒ‰éˆ•
        4. **æŸ¥çœ‹çµæœ**: åœ¨å°æ¯”è¦–çª—ä¸­æŸ¥çœ‹åŸæ–‡ä»¶èˆ‡è­˜åˆ¥çµæœ
        5. **ä¸‹è¼‰æ–‡ä»¶**: ä¸‹è¼‰TXTæˆ–JSONæ ¼å¼çµæœ
        6. **æ­·å²è¨˜éŒ„**: åœ¨å´é‚Šæ¬„æŸ¥çœ‹å’Œé‡æ–°ä¸‹è¼‰æ­·å²çµæœ
        
        #### âš™ï¸ æŠ€è¡“åƒæ•¸
        
        - **åœ–åƒDPI**: å¯èª¿æ•´ï¼Œå»ºè­°300-600
        - **èªè¨€æ”¯æŒ**: ç°¡é«”ä¸­æ–‡ã€ç¹é«”ä¸­æ–‡ã€è‹±æ–‡
        - **è™•ç†æ™‚é–“**: æ ¹æ“šæ–‡ä»¶å¤§å°å’Œé æ•¸è€Œå®š
        - **æ–‡å­—ä¿ç•™**: å®Œå…¨ä¿ç•™åŸå§‹æ–‡å­—æ¨£å¼å’Œæ–·å¥
        
        #### ğŸ”§ ç³»çµ±è¦æ±‚
        
        - æ”¯æŒPDFæ ¼å¼æ–‡ä»¶
        - å»ºè­°æ–‡ä»¶å¤§å°ä¸è¶…é50MB
        - è™•ç†æ™‚é–“èˆ‡æ–‡ä»¶å¤§å°æˆæ­£æ¯”
        """)

if __name__ == "__main__":
    main()
